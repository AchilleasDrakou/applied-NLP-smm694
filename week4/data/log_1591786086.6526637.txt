2020-06-10 11:51:28,850 : INFO : collecting all words and their counts
2020-06-10 11:51:28,851 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types
2020-06-10 11:51:29,006 : INFO : pruned out 0 tokens with count <=1 (before 50016, after 50016)
2020-06-10 11:51:29,023 : INFO : pruned out 41505 tokens with count <=2 (before 50055, after 8550)
2020-06-10 11:51:29,051 : INFO : collected 19649 word types from a corpus of 65677 words (unigram + bigrams) and 1156 sentences
2020-06-10 11:51:29,051 : INFO : using 19649 counts as vocab in Phrases<0 vocab, min_count=50, threshold=5, max_vocab_size=50000>
2020-06-10 11:51:29,052 : INFO : collecting all words and their counts
2020-06-10 11:51:29,052 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types
2020-06-10 11:51:29,347 : INFO : pruned out 0 tokens with count <=1 (before 50020, after 50020)
2020-06-10 11:51:29,369 : INFO : pruned out 41509 tokens with count <=2 (before 50059, after 8550)
2020-06-10 11:51:29,453 : INFO : collected 19650 word types from a corpus of 65521 words (unigram + bigrams) and 1156 sentences
2020-06-10 11:51:29,453 : INFO : using 19650 counts as vocab in Phrases<0 vocab, min_count=50, threshold=5, max_vocab_size=50000>
2020-06-10 11:51:34,769 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2020-06-10 11:51:34,985 : INFO : built Dictionary(7464 unique tokens: ['activity', 'analyze', 'art', 'articulate', 'ask']...) from 1156 documents (total 65463 corpus positions)
2020-06-10 11:51:42,439 : INFO : serializing temporary corpus to /tmp/84d205_corpus.txt
2020-06-10 11:51:42,585 : INFO : converting temporary corpus to MALLET format with mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex "\S+" --input /tmp/84d205_corpus.txt --output /tmp/84d205_corpus.mallet
2020-06-10 11:54:40,893 : INFO : serializing temporary corpus to /tmp/55aa0a_corpus.txt
2020-06-10 11:54:41,036 : INFO : converting temporary corpus to MALLET format with /home/simone/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex "\S+" --input /tmp/55aa0a_corpus.txt --output /tmp/55aa0a_corpus.mallet
2020-06-10 11:54:41,685 : INFO : training MALLET LDA with /home/simone/mallet-2.0.8/bin/mallet train-topics --input /tmp/55aa0a_corpus.mallet --num-topics 29  --alpha 50 --optimize-interval 0 --num-threads 4 --output-state /tmp/55aa0a_state.mallet.gz --output-doc-topics /tmp/55aa0a_doctopics.txt --output-topic-keys /tmp/55aa0a_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/55aa0a_inferencer.mallet --doc-topics-threshold 0.0  --random-seed 123
2020-06-10 11:55:18,308 : INFO : loading assigned topics from /tmp/55aa0a_state.mallet.gz
2020-06-10 11:55:18,575 : INFO : topic #0 (1.724): 0.072*"difference" + 0.066*"type" + 0.030*"style" + 0.024*"identify" + 0.022*"individual"
2020-06-10 11:55:18,575 : INFO : topic #1 (1.724): 0.138*"development" + 0.052*"potential" + 0.037*"develop" + 0.029*"feedback" + 0.027*"longitudinal"
2020-06-10 11:55:18,575 : INFO : topic #2 (1.724): 0.068*"role" + 0.056*"lead" + 0.047*"goal" + 0.040*"impact" + 0.038*"motivation"
2020-06-10 11:55:18,575 : INFO : topic #3 (1.724): 0.118*"level" + 0.064*"skill" + 0.061*"high" + 0.036*"orientation" + 0.035*"career"
2020-06-10 11:55:18,575 : INFO : topic #4 (1.724): 0.085*"perspective" + 0.046*"understanding" + 0.045*"knowledge" + 0.027*"integrate" + 0.024*"science"
2020-06-10 11:55:18,576 : INFO : topic #5 (1.724): 0.074*"power" + 0.031*"suggest" + 0.031*"explore" + 0.023*"assessment" + 0.021*"consequence"
2020-06-10 11:55:18,576 : INFO : topic #6 (1.724): 0.115*"effectiveness" + 0.040*"analysis" + 0.030*"conduct" + 0.029*"moderator" + 0.025*"investigate"
2020-06-10 11:55:18,576 : INFO : topic #7 (1.724): 0.079*"role" + 0.078*"woman" + 0.046*"gender" + 0.042*"female" + 0.030*"position"
2020-06-10 11:55:18,576 : INFO : topic #8 (1.724): 0.055*"vision" + 0.042*"strategy" + 0.036*"proposition" + 0.036*"effective" + 0.035*"understand"
2020-06-10 11:55:18,576 : INFO : topic #9 (1.724): 0.055*"positively" + 0.046*"work" + 0.040*"psychological" + 0.039*"mediate" + 0.033*"perceive"
2020-06-10 11:55:18,576 : INFO : topic #10 (1.724): 0.087*"affect" + 0.081*"positive" + 0.075*"negative" + 0.075*"emotion" + 0.069*"emotional"
2020-06-10 11:55:18,577 : INFO : topic #11 (1.724): 0.084*"rating" + 0.047*"report" + 0.040*"rate" + 0.026*"peer" + 0.026*"variance"
2020-06-10 11:55:18,577 : INFO : topic #12 (1.724): 0.048*"political" + 0.025*"quarterly" + 0.024*"special" + 0.022*"direction" + 0.020*"decade"
2020-06-10 11:55:18,577 : INFO : topic #13 (1.724): 0.114*"subordinate" + 0.109*"lmx" + 0.053*"work" + 0.050*"quality" + 0.041*"exchange"
2020-06-10 11:55:18,577 : INFO : topic #14 (1.724): 0.087*"perception" + 0.064*"perceive" + 0.062*"identity" + 0.041*"increase" + 0.039*"show"
2020-06-10 11:55:18,577 : INFO : topic #15 (1.724): 0.066*"trait" + 0.056*"ability" + 0.048*"personality" + 0.041*"experience" + 0.041*"predict"
2020-06-10 11:55:18,577 : INFO : topic #16 (1.724): 0.064*"authentic" + 0.046*"climate" + 0.041*"develop" + 0.030*"antecedent" + 0.024*"analyze"
2020-06-10 11:55:18,578 : INFO : topic #17 (1.724): 0.233*"team" + 0.180*"transformational" + 0.041*"member" + 0.034*"share" + 0.034*"transactional"
2020-06-10 11:55:18,578 : INFO : topic #18 (1.724): 0.139*"charismatic" + 0.068*"charisma" + 0.059*"time" + 0.043*"change" + 0.034*"content"
2020-06-10 11:55:18,578 : INFO : topic #19 (1.724): 0.055*"structure" + 0.050*"network" + 0.032*"action" + 0.029*"form" + 0.027*"situation"
2020-06-10 11:55:18,578 : INFO : topic #20 (1.724): 0.036*"purpose" + 0.029*"include" + 0.028*"question" + 0.026*"method" + 0.025*"explore"
2020-06-10 11:55:18,578 : INFO : topic #21 (1.724): 0.094*"manager" + 0.071*"management" + 0.062*"ethical" + 0.044*"moral" + 0.039*"behavioral"
2020-06-10 11:55:18,578 : INFO : topic #22 (1.724): 0.055*"context" + 0.043*"dynamic" + 0.036*"emerge" + 0.035*"system" + 0.032*"contexts"
2020-06-10 11:55:18,579 : INFO : topic #23 (1.724): 0.281*"performance" + 0.081*"ceo" + 0.049*"firm" + 0.040*"strategic" + 0.031*"executive"
2020-06-10 11:55:18,579 : INFO : topic #24 (1.724): 0.067*"change" + 0.065*"practice" + 0.036*"culture" + 0.035*"conflict" + 0.029*"importance"
2020-06-10 11:55:18,579 : INFO : topic #25 (1.724): 0.052*"problem" + 0.045*"identify" + 0.044*"creative" + 0.042*"relation" + 0.041*"creativity"
2020-06-10 11:55:18,579 : INFO : topic #26 (1.724): 0.199*"group" + 0.082*"task" + 0.050*"member" + 0.045*"condition" + 0.040*"collective"
2020-06-10 11:55:18,579 : INFO : topic #27 (1.724): 0.151*"employee" + 0.066*"job" + 0.063*"supervisor" + 0.047*"trust" + 0.043*"commitment"
2020-06-10 11:55:18,579 : INFO : topic #28 (1.724): 0.048*"work" + 0.035*"view" + 0.035*"event" + 0.026*"interest" + 0.025*"context"
2020-06-10 11:57:11,894 : INFO : using serial LDA version on this node
2020-06-10 11:57:13,152 : INFO : NumExpr defaulting to 8 threads.
2020-06-10 13:17:34,500 : INFO : collecting all words and their counts
2020-06-10 13:17:34,501 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types
2020-06-10 13:17:34,758 : INFO : pruned out 0 tokens with count <=1 (before 50016, after 50016)
2020-06-10 13:17:34,785 : INFO : pruned out 41505 tokens with count <=2 (before 50055, after 8550)
2020-06-10 13:17:34,819 : INFO : collected 19649 word types from a corpus of 65677 words (unigram + bigrams) and 1156 sentences
2020-06-10 13:17:34,819 : INFO : using 19649 counts as vocab in Phrases<0 vocab, min_count=50, threshold=5, max_vocab_size=50000>
2020-06-10 13:17:34,821 : INFO : collecting all words and their counts
2020-06-10 13:17:34,822 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types
2020-06-10 13:17:35,311 : INFO : pruned out 0 tokens with count <=1 (before 50020, after 50020)
2020-06-10 13:17:35,335 : INFO : pruned out 41509 tokens with count <=2 (before 50059, after 8550)
2020-06-10 13:17:35,512 : INFO : collected 19650 word types from a corpus of 65521 words (unigram + bigrams) and 1156 sentences
2020-06-10 13:17:35,513 : INFO : using 19650 counts as vocab in Phrases<0 vocab, min_count=50, threshold=5, max_vocab_size=50000>
2020-06-10 13:21:28,682 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2020-06-10 13:21:28,856 : INFO : built Dictionary(7464 unique tokens: ['activity', 'analyze', 'art', 'articulate', 'ask']...) from 1156 documents (total 65463 corpus positions)
